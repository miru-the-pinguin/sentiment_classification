{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9f3fQacyrKT"
   },
   "source": [
    "# Modely by Topic\n",
    "\n",
    "Here an attempt is made to fit a model for one topic and test it on the 4 other topics. This can reveal similarities between text from different topics.\n",
    "\n",
    "The hyperparameters will not be optimized again, as this is not the main part of the research, but will be taken from previous optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBf4whpszY4H"
   },
   "source": [
    "##  Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19328,
     "status": "ok",
     "timestamp": 1745784059061,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "JpFSkI9bzlVj",
    "outputId": "f2fb62b3-f08a-4bcf-f617-01b977866432"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3824,
     "status": "ok",
     "timestamp": 1745784062886,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "kaRqoHqSyLsk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the correct file path\n",
    "file_path_train = \"/content/drive/My Drive/BA THESIS/data/train_NB_lem.csv\"\n",
    "#file_path_val = \"/content/drive/My Drive/BA THESIS/data/val_NB_lem.csv\"\n",
    "file_path_test = \"/content/drive/My Drive/BA THESIS/data/test_NB_lem.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "train_NB_lem = pd.read_csv(file_path_train)\n",
    "#val_NB_lem = pd.read_csv(file_path_val)\n",
    "test_NB_lem = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1745784063973,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "6tISNYvpzlqU"
   },
   "outputs": [],
   "source": [
    "# Provide the correct file path\n",
    "file_path_train = \"/content/drive/My Drive/BA THESIS/data/train_BERT.csv\"\n",
    "#file_path_val = \"/content/drive/My Drive/BA THESIS/data/val_BERT.csv\"\n",
    "file_path_test = \"/content/drive/My Drive/BA THESIS/data/test_BERT.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "train_BERT = pd.read_csv(file_path_train)\n",
    "#val_BERT = pd.read_csv(file_path_val)\n",
    "test_BERT = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRfdU-KQ071J"
   },
   "source": [
    "## Fitting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONG32hu84Mdl"
   },
   "source": [
    "We fit a naive BAyes and a BERT model on each subset of the training data by topic and run a prediciton for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1745784064496,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "99Y7paIJ4sDy"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745784064511,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "n7l6eVHa07c8"
   },
   "outputs": [],
   "source": [
    "# function to fit a models on a given subset and then run the classification and return the classification\n",
    "\n",
    "def NB_on_subset (topic):\n",
    "\n",
    "  #tarining:\n",
    "  train_data = train_NB_lem[train_NB_lem['topic'] == topic]\n",
    "  x = train_data['text']\n",
    "  y = train_data['ground_truth']\n",
    "\n",
    "  vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=20000)\n",
    "  X_train_count = vectorizer.fit_transform(x)\n",
    "\n",
    "  nb = MultinomialNB(alpha = 1)\n",
    "  nb.fit(X_train_count, y)\n",
    "\n",
    "  # testing\n",
    "  x_test = vectorizer.transform(test_NB_lem['text'])\n",
    "  y_test = test_NB_lem['ground_truth']\n",
    "  y_pred = nb.predict(x_test)\n",
    "\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1745784064725,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "Z_e5xO1R4jGl"
   },
   "outputs": [],
   "source": [
    "nb_finance_preds = NB_on_subset(\"finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745784064885,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "qJXL0Gy45TEB"
   },
   "outputs": [],
   "source": [
    "nb_news_preds = NB_on_subset(\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1745784065158,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "sMZtjzFL5XSi"
   },
   "outputs": [],
   "source": [
    "nb_reddit_pred = NB_on_subset(\"reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1745784066222,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "Zx4vSi4k5jST"
   },
   "outputs": [],
   "source": [
    "nb_twitter_preds = NB_on_subset(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745784066642,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "GMRDnNbJ0LoV"
   },
   "outputs": [],
   "source": [
    "train_NB_lem.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1745784067914,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "vDqopntK5o8C"
   },
   "outputs": [],
   "source": [
    "nb_movie_preds = NB_on_subset(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10129,
     "status": "ok",
     "timestamp": 1745784080515,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "2kD_uh896w5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1745784080534,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ZXnA_qsK5zHW"
   },
   "outputs": [],
   "source": [
    "# function to fit a models on a given subset and then run the classification and return the classification\n",
    "\n",
    "def BERT_on_subset (topic):\n",
    "\n",
    "  train_data = train_BERT[train_BERT['topic'] == topic]\n",
    "  test_data = test_BERT.copy()\n",
    "\n",
    "  # encode labels\n",
    "  label_encoder = LabelEncoder()\n",
    "  train_data[\"label\"] = label_encoder.fit_transform(train_data[\"ground_truth\"])\n",
    "  test_data[\"label\"] = label_encoder.transform(test_data[\"ground_truth\"])\n",
    "\n",
    "  tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "  def tokenize_function(text):\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",    # or use \"longest\" for dynamic padding\n",
    "        max_length=200,       # since we are using headlines\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "  # Tokenize texts and extract tensors\n",
    "  tokenized_train = tokenize_function(train_data[\"text\"].tolist())\n",
    "  tokenized_test = tokenize_function(test_data[\"text\"].tolist())\n",
    "\n",
    "  # Convert labels to a TensorFlow tensor\n",
    "  labels_train = tf.convert_to_tensor(train_data[\"label\"].tolist())\n",
    "  labels_test = tf.convert_to_tensor(test_data[\"label\"].tolist())\n",
    "\n",
    "  # Create a dataset from the dictionary and labels\n",
    "  dataset_train = tf.data.Dataset.from_tensor_slices((\n",
    "      {\n",
    "          \"input_ids\": tokenized_train[\"input_ids\"],\n",
    "          \"attention_mask\": tokenized_train[\"attention_mask\"]\n",
    "      },\n",
    "      labels_train\n",
    "  ))\n",
    "\n",
    "  dataset_test = tf.data.Dataset.from_tensor_slices((\n",
    "      {\n",
    "          \"input_ids\": tokenized_test[\"input_ids\"],\n",
    "          \"attention_mask\": tokenized_test[\"attention_mask\"]\n",
    "      },\n",
    "      labels_test\n",
    "  ))\n",
    "\n",
    "  batch_size = 16\n",
    "  dataset_train = dataset_train.shuffle(buffer_size=len(train_BERT)).batch(batch_size)\n",
    "\n",
    "  model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "  # Compile the model with an optimizer, loss, and metrics\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  num_epochs = 2\n",
    "  history = model.fit(\n",
    "      dataset_train,\n",
    "#      validation_data=dataset_val,\n",
    "      epochs=num_epochs\n",
    "  )\n",
    "\n",
    "  # testing\n",
    "\n",
    "  logits = model.predict(tokenized_test).logits\n",
    "\n",
    "  # Convert logits to class predictions\n",
    "  y_pred_bert = tf.argmax(logits, axis=-1).numpy()\n",
    "\n",
    "  label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "  predicted_labels_bert = [label_map[pred] for pred in y_pred_bert]\n",
    "\n",
    "  return predicted_labels_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596,
     "referenced_widgets": [
      "172462215c494ebc8f5094ce57fb1bfa",
      "a4ae60a9622f46ebaad7aed96a992697",
      "7daacb88e97c47f1abb2e51b50a6180c",
      "29ad2807472a4af091227311f9b66625",
      "26db66f1cef645f58a2b8b469db7544e",
      "975804143c41494aac23b7762dfaf038",
      "9016687ae11945b591627080cf65857f",
      "c2fe3ebb7f944597aa9782aebc81bd08",
      "cd0d8c8be96742029626046a808a3be6",
      "d11869ef7a884d78af0587fe368bb046",
      "31702fb809044fca974fe549aa8534d6",
      "1980521fe5d64b04a525b1124d37e855",
      "e98a53b6d0974a2785b1997ed7d35b0d",
      "797e4be90b794dc38bb65030422fe171",
      "06f72ab685fc4d89b10deb70cb77cb1c",
      "67f7728b70b44e74a091ec9a3c23ce6d",
      "301dddf78bbd41fbbbbcfa784d45db73",
      "9be3c87c53bf46a9bfff8dbca9ebcc5a",
      "1f53f2018e6d4b32bd339ebcbf8cabc7",
      "185a69b53ba84871ae876dc31dd7d323",
      "4f48231ac1e84f2092beaf089942f2fa",
      "4f4125e0f3184983b4ac9d33d0acf8f5",
      "48198d1e39354168b4b229653ea3a893",
      "6559a9d73db64111aa6a354bb9c05fd3",
      "d3504fc31cff4b708ce6a005914d4072",
      "db29c4bfee2f4c48a13f8e662181c839",
      "7f618c400a564592848fbb43d52474c3",
      "94d59f8db9c844bf9004a53ded69e61a",
      "2f61c665678245aea020e984159c53b3",
      "f809deeefa754474b21719a0b8c15dc6",
      "2c702c394e204b35b20de1e0189247e0",
      "7d8b099bfa244846a423776be0599e55",
      "362fd98d94504c84b94e1d4b2b65e935",
      "935904777701429585f2c3b17208c31d",
      "78194c6f95cc46db8a591220200d6943",
      "dac93a19041542c782ec921365d5beff",
      "f12d393d410f47c2a2a27ed7086a4c17",
      "0ee6bc34d2f14e83a3888140aa2dd073",
      "c6d2c8dee7344c6d9e56d53b2c69cd6b",
      "bd228f8ed8674eaca781c22b1b1b7a53",
      "fd19b0c37aac4f4a9dac687045d5f70d",
      "e81b18d446f64dcd857e108d359b9a85",
      "0885f145f7fa4fb8a54ae3b669de0c3b",
      "18b8f6be309242eb8c089d06f110554e",
      "38b77807fd0a46879cacf71a76b3a9ff",
      "73769aaf711b46e8aa6f3bdcf81ee1c8",
      "331f1bb5a9a94c34bee407da59ca91ca",
      "749753fe60e648f7883c91b408c194f7",
      "19c0bd01f4a842dfb982b6c09b56839f",
      "14a8bcb5918d4bb1be964eda7289b4ba",
      "bac5ae1a74e94518bf1cdc90e4094eae",
      "3e20cc2b84544042b05118473645ba7e",
      "5e239d86ac6f4217a22a0e351706aca2",
      "abbfd9681cdd4897ae06f7a301572b38",
      "2c12cbfb79ca4a22a86dc19ecf38a3c2"
     ]
    },
    "executionInfo": {
     "elapsed": 124658,
     "status": "ok",
     "timestamp": 1745784205194,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "Ggh8NI5g80aZ",
    "outputId": "3ecaaf1c-73ce-4fd5-db4d-457ebb9d8c42"
   },
   "outputs": [],
   "source": [
    "bert_finance_preds = BERT_on_subset(\"finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155193,
     "status": "ok",
     "timestamp": 1745784365373,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "1XiD3VH49epU",
    "outputId": "ec541f26-8d97-4c69-bef2-f3314282a8eb"
   },
   "outputs": [],
   "source": [
    "bert_news_preds = BERT_on_subset(\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301412,
     "status": "ok",
     "timestamp": 1745784666790,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "yeZNC_e--832",
    "outputId": "363a6f3f-04d3-4233-8333-2d7619029fd2"
   },
   "outputs": [],
   "source": [
    "bert_reddit_preds = BERT_on_subset(\"reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224000,
     "status": "ok",
     "timestamp": 1745784890792,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "x9azn9dU_AnD",
    "outputId": "66943efd-7ef7-4658-b4a0-2f3129cb5b40"
   },
   "outputs": [],
   "source": [
    "bert_twitter_preds = BERT_on_subset(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206843,
     "status": "ok",
     "timestamp": 1745785097646,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "0Xn1wa9d_GPD",
    "outputId": "7e3fa745-2e05-4ac3-f9a1-a49134396db7"
   },
   "outputs": [],
   "source": [
    "bert_movie_preds = BERT_on_subset(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745785133484,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "0qlKq_8rCdXR"
   },
   "outputs": [],
   "source": [
    "# create a data frame with all predictions\n",
    "\n",
    "all_preds_subsets = pd.DataFrame({\n",
    "    'Text': test_BERT['text'],\n",
    "    'Topic': test_NB_lem['topic'],\n",
    "    'Actual': test_NB_lem['ground_truth'],\n",
    "    'NB_finance': nb_finance_preds,\n",
    "    'BERT_finance': bert_finance_preds,\n",
    "    'NB_news': nb_news_preds,\n",
    "    'BERT_news': bert_news_preds,\n",
    "    'NB_reddit': nb_reddit_pred,\n",
    "    'BERT_reddit': bert_reddit_preds,\n",
    "    'NB_twitter': nb_twitter_preds,\n",
    "    'BERT_twitter': bert_twitter_preds,\n",
    "    'NB_movie': nb_movie_preds,\n",
    "    'BERT_movie': bert_movie_preds\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1745785137525,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "6kY_AokCC43s",
    "outputId": "78f6c03c-92c5-4013-cc25-c778c7402848"
   },
   "outputs": [],
   "source": [
    "all_preds_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1745785141614,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "L-f2FHWODW3h"
   },
   "outputs": [],
   "source": [
    "all_preds_subsets.to_csv('/content/drive/My Drive/BA THESIS/analysis/all_preds_subsets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ5bFdKJDb-0"
   },
   "source": [
    "Now the analysis of performance of these models trained on only a sinle topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1745785146191,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "Y3ZHQGUJDv5q",
    "outputId": "67d8f681-2549-498a-b7f9-c980ca831b59"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy(predictions, actual):\n",
    "    correct_predictions = np.sum(np.array(predictions) == np.array(actual))\n",
    "    return correct_predictions / len(actual)\n",
    "\n",
    "def create_diamond_chart(ax, model_name, topic_accuracies):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "    ax.fill(angles, values, 'skyblue', alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "\n",
    "    ax.set_title(f\"{model_name} Accuracy\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Calculate accuracies for NB_finance\n",
    "nb_finance_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][f\"NB_{topic.lower().replace(' ', '_')}\"].tolist()\n",
    "    nb_finance_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_finance\n",
    "bert_finance_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][f\"BERT_{topic.lower().replace(' ', '_')}\"].tolist()\n",
    "    bert_finance_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), subplot_kw={'polar': True})\n",
    "\n",
    "\n",
    "# Create the diamond chart for NB_finance\n",
    "create_diamond_chart(ax1, \"NB_finance\", nb_finance_topic_accuracies)\n",
    "\n",
    "# Create the diamond chart for BERT_finance\n",
    "create_diamond_chart(ax2, \"BERT_finance\", bert_finance_topic_accuracies)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1745785165394,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "6TBfupklFHkS",
    "outputId": "1cf1ce36-0386-4150-948e-bb63f58b9662"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "\n",
    "def create_diamond_chart(ax, model_name, topic_accuracies, color):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', color=color)\n",
    "    ax.fill(angles, values, color, alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "    ax.set_rlim(0,1)\n",
    "\n",
    "    ax.set_title(f\"Performance of model trained on 'finance' data\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Assuming all_preds_subsets DataFrame is already available\n",
    "\n",
    "# Calculate accuracies for NB_finance\n",
    "nb_finance_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"NB_finance\"].tolist()\n",
    "    nb_finance_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_finance\n",
    "bert_finance_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"BERT_finance\"].tolist()\n",
    "    bert_finance_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'polar': True})\n",
    "\n",
    "# Plot NB_finance data\n",
    "create_diamond_chart(ax, \"NB_finance\", nb_finance_topic_accuracies, \"blue\")\n",
    "\n",
    "# Plot BERT_finance data\n",
    "create_diamond_chart(ax, \"BERT_finance\", bert_finance_topic_accuracies, \"green\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', lw=2, label='Naive Bayes'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='BERT')\n",
    "]\n",
    "#ax.legend([\"Naive Bayes\", \"BERT\"], loc=\"upper right\")\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/analysis/performance_finance.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1745785179147,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "OSbZbWkyHm7V",
    "outputId": "6a7b8b71-0caa-4fe1-96b4-7f5d96e9a411"
   },
   "outputs": [],
   "source": [
    "def create_diamond_chart(ax, model_name, topic_accuracies, color):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', color=color)\n",
    "    ax.fill(angles, values, color, alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "    ax.set_rlim(0,1)\n",
    "\n",
    "    ax.set_title(f\"Performance of model trained on 'news' data\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Assuming all_preds_subsets DataFrame is already available\n",
    "\n",
    "# Calculate accuracies for NB_news\n",
    "nb_news_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"NB_news\"].tolist()\n",
    "    nb_news_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_news\n",
    "bert_news_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"BERT_news\"].tolist()\n",
    "    bert_news_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'polar': True})\n",
    "\n",
    "# Plot NB_news data\n",
    "create_diamond_chart(ax, \"NB_news\", nb_news_topic_accuracies, \"blue\")\n",
    "\n",
    "# Plot BERT_news data\n",
    "create_diamond_chart(ax, \"BERT_news\", bert_news_topic_accuracies, \"green\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', lw=2, label='Naive Bayes'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='BERT')\n",
    "]\n",
    "#ax.legend([\"Naive Bayes\", \"BERT\"], loc=\"upper right\")\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/analysis/performance_news.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1745785185924,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "2zSNw0ZfJffJ",
    "outputId": "e03b7786-f34a-4eff-cd0d-b9b7beffb2f7"
   },
   "outputs": [],
   "source": [
    "def create_diamond_chart(ax, model_name, topic_accuracies, color):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', color=color)\n",
    "    ax.fill(angles, values, color, alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "    ax.set_rlim(0,1)\n",
    "\n",
    "    ax.set_title(f\"Performance of model trained on 'reddit' data\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Assuming all_preds_subsets DataFrame is already available\n",
    "\n",
    "# Calculate accuracies for NB_reddit\n",
    "nb_reddit_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"NB_reddit\"].tolist()\n",
    "    nb_reddit_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_reddit\n",
    "bert_reddit_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"BERT_reddit\"].tolist()\n",
    "    bert_reddit_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'polar': True})\n",
    "\n",
    "# Plot NB_reddit data\n",
    "create_diamond_chart(ax, \"NB_reddit\", nb_reddit_topic_accuracies, \"blue\")\n",
    "\n",
    "# Plot BERT_reddit data\n",
    "create_diamond_chart(ax, \"BERT_reddit\", bert_reddit_topic_accuracies, \"green\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', lw=2, label='Naive Bayes'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='BERT')\n",
    "]\n",
    "#ax.legend([\"Naive Bayes\", \"BERT\"], loc=\"upper right\")\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/analysis/performance_reddit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1745785207263,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ez3ukFuQJ_1-",
    "outputId": "392ecdc8-4d71-4492-b672-04caaa3c65a0"
   },
   "outputs": [],
   "source": [
    "def create_diamond_chart(ax, model_name, topic_accuracies, color):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', color=color)\n",
    "    ax.fill(angles, values, color, alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "    ax.set_rlim(0,1)\n",
    "\n",
    "    ax.set_title(f\"Performance of model trained on 'twitter' data\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Assuming all_preds_subsets DataFrame is already available\n",
    "\n",
    "# Calculate accuracies for NB_twitter\n",
    "nb_twitter_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"NB_twitter\"].tolist()\n",
    "    nb_twitter_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_twitter\n",
    "bert_twitter_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"BERT_twitter\"].tolist()\n",
    "    bert_twitter_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'polar': True})\n",
    "\n",
    "# Plot NB_twitter data\n",
    "create_diamond_chart(ax, \"NB_twitter\", nb_twitter_topic_accuracies, \"blue\")\n",
    "\n",
    "# Plot BERT_twitter data\n",
    "create_diamond_chart(ax, \"BERT_twitter\", bert_twitter_topic_accuracies, \"green\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', lw=2, label='Naive Bayes'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='BERT')\n",
    "]\n",
    "#ax.legend([\"Naive Bayes\", \"BERT\"], loc=\"upper right\")\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/analysis/performance_twitter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1745785231058,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "UPwpwXRTK8jy",
    "outputId": "81a384d6-1793-43d0-932e-b2ae5bd124ad"
   },
   "outputs": [],
   "source": [
    "def create_diamond_chart(ax, model_name, topic_accuracies, color):\n",
    "    topics = list(topic_accuracies.keys())\n",
    "    accuracies = list(topic_accuracies.values())\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(topics), endpoint=False).tolist()\n",
    "    values = accuracies + [accuracies[0]]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', color=color)\n",
    "    ax.fill(angles, values, color, alpha=0.4)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), topics)\n",
    "    ax.set_rlim(0,1)\n",
    "\n",
    "    ax.set_title(f\"Performance of model trained on 'movie' data\")\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Assuming all_preds_subsets DataFrame is already available\n",
    "\n",
    "# Calculate accuracies for NB_movie\n",
    "nb_movie_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"NB_movie\"].tolist()\n",
    "    nb_movie_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "\n",
    "# Calculate accuracies for BERT_movie\n",
    "bert_movie_topic_accuracies = {}\n",
    "for topic in [\"finance\", \"news\", \"reddit\", \"twitter\", \"movie\"]:\n",
    "    actual_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"Actual\"].tolist()\n",
    "    predicted_labels = all_preds_subsets[all_preds_subsets[\"Topic\"] == topic][\"BERT_movie\"].tolist()\n",
    "    bert_movie_topic_accuracies[topic] = calculate_accuracy(predicted_labels, actual_labels)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'polar': True})\n",
    "\n",
    "# Plot NB_movie data\n",
    "create_diamond_chart(ax, \"NB_movie\", nb_movie_topic_accuracies, \"blue\")\n",
    "\n",
    "# Plot BERT_movie data\n",
    "create_diamond_chart(ax, \"BERT_movie\", bert_movie_topic_accuracies, \"green\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', lw=2, label='Naive Bayes'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='BERT')\n",
    "]\n",
    "#ax.legend([\"Naive Bayes\", \"BERT\"], loc=\"upper right\")\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/analysis/performance_movie.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN5hgvgLwE5OR7M33wmT7IF",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
