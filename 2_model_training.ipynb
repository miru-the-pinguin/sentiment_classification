{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxAzDI8eHquy"
   },
   "source": [
    "##Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVLP5u9lMkdx"
   },
   "source": [
    "Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2526,
     "status": "ok",
     "timestamp": 1745770548089,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "_qMk1kOVGwEG",
    "outputId": "a4d86986-f9e8-4657-ba51-618e251d89aa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1745776396492,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "3oxr9aIEIMR7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the correct file path\n",
    "file_path_train = \"/content/drive/My Drive/BA THESIS/data/train_NB_lem.csv\"\n",
    "file_path_val = \"/content/drive/My Drive/BA THESIS/data/val_NB_lem.csv\"\n",
    "#file_path_test = \"/content/drive/My Drive/BA THESIS/data/test_NB_lem.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "train_NB_lem = pd.read_csv(file_path_train)\n",
    "val_NB_lem = pd.read_csv(file_path_val)\n",
    "#test_NB_lem = pd.read_csv(file_path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1745778293909,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "7ug4VETzy9PM"
   },
   "outputs": [],
   "source": [
    "# Provide the correct file path\n",
    "file_path_train = \"/content/drive/My Drive/BA THESIS/data/train_NB_stem.csv\"\n",
    "file_path_val = \"/content/drive/My Drive/BA THESIS/data/val_NB_stem.csv\"\n",
    "#file_path_test = \"/content/drive/My Drive/BA THESIS/data/test_NB_stem.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "train_NB_stem = pd.read_csv(file_path_train)\n",
    "val_NB_stem = pd.read_csv(file_path_val)\n",
    "#test_NB_stem = pd.read_csv(file_path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1745778297411,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ru7KgG0qOb-I"
   },
   "outputs": [],
   "source": [
    "# Provide the correct file path\n",
    "file_path_train = \"/content/drive/My Drive/BA THESIS/data/train_BERT.csv\"\n",
    "file_path_val = \"/content/drive/My Drive/BA THESIS/data/val_BERT.csv\"\n",
    "#file_path_test = \"/content/drive/My Drive/BA THESIS/data/test_BERT.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "train_BERT = pd.read_csv(file_path_train)\n",
    "val_BERT = pd.read_csv(file_path_val)\n",
    "#test_BERT = pd.read_csv(file_path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1745778335432,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "uS3AhH2UfuEj",
    "outputId": "5944b21d-fec6-457b-d058-ce5ed48ef04c"
   },
   "outputs": [],
   "source": [
    "print(train_NB_lem.isna().sum(), train_NB_stem.isna().sum(), train_BERT.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1745778434997,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ZJsxJMB0gMe-",
    "outputId": "57159f7d-6587-4f69-faf9-353d4b31bbf4"
   },
   "outputs": [],
   "source": [
    "print(val_NB_lem.isna().sum(), val_NB_stem.isna().sum(), val_BERT.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745778463748,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "i_qW3EjGf3yB"
   },
   "outputs": [],
   "source": [
    "# two additional NAs need to be removed from stemmed and lemmatized sets\n",
    "\n",
    "train_NB_lem = train_NB_lem.dropna()\n",
    "train_NB_stem = train_NB_stem.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_lSjBE2y1RE"
   },
   "source": [
    "# Naive Bayes model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkvPQ8ln4AJp"
   },
   "source": [
    "Both lemmatizing and stemming datasets will be used separately and the highest validation accuracy will chose, which method will be carreid on. The intuition behind this is that with stemming the occurences of words (stems) will be higher as it uses brute force to stem words and allows for less stems and more reduction comapred to lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745777607229,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ZZCnTpFBQGLu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1745777608755,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "I6fdQx1yP0VQ"
   },
   "outputs": [],
   "source": [
    "def best_parameter_search (vectorizer, X_train, y_train, X_val, y_val):\n",
    "\n",
    "  pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', MultinomialNB())\n",
    "  ])\n",
    "\n",
    "  # Grid of hyperparameters\n",
    "  param_grid = {\n",
    "      'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "      'vectorizer__max_features': [5000, 10000, 15000, 20000, 25000],\n",
    "      'classifier__alpha': [0.1, 0.5, 1.0]\n",
    "  }\n",
    "\n",
    "  # Grid search only on training data\n",
    "  grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  # Best model from grid search\n",
    "  best_model = grid_search.best_estimator_\n",
    "\n",
    "  # Evaluate on validation set\n",
    "  y_pred = best_model.predict(X_val)\n",
    "\n",
    "  # Print evaluation metrics\n",
    "  print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "  print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "  print(\"Best Parameters:\", grid_search.best_params_)\n",
    "  print(\"Best Cross-Validation Score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpq6TMxE39Pw"
   },
   "source": [
    "## Lemmatizing vs Stemming (with different vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1745778472614,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "XX4VBl54PrvR"
   },
   "outputs": [],
   "source": [
    "x_lem = train_NB_lem['text']\n",
    "y_lem = train_NB_lem['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745778473625,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "1p1b2caCR3xG"
   },
   "outputs": [],
   "source": [
    "x_lem_val = val_NB_lem['text']\n",
    "y_lem_val = val_NB_lem['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745778474643,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "wK76Nl08TB5n"
   },
   "outputs": [],
   "source": [
    "x_stem = train_NB_stem['text']\n",
    "y_stem = train_NB_stem['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745778475693,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "9mOy2IlXTKS4"
   },
   "outputs": [],
   "source": [
    "x_stem_val = val_NB_stem['text']\n",
    "y_stem_val = val_NB_stem['ground_truth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1chFzjrFTXZ"
   },
   "source": [
    "### TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGenmwDdXj3A"
   },
   "source": [
    "Parameters:\n",
    "- ngram_range: (1,1) or (1,2)\n",
    "- max_features: 5000, 10 000, 15 000, 20 0000, 25 000\n",
    "- alpha: 0.1, 0.5 and 1\n",
    "\n",
    "The best parameters are ngram_range (1,1), max features 10,000 for lemmatized and 25,000 for stemmed set and alpha 1. On the lemmatized set the model performs marginally better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10739,
     "status": "ok",
     "timestamp": 1745778500159,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "TMjRIgkBRuFF",
    "outputId": "974320c3-42d0-4443-f88c-5e0d593a01c8"
   },
   "outputs": [],
   "source": [
    "best_parameter_search (TfidfVectorizer(), x_lem, y_lem, x_lem_val, y_lem_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9503,
     "status": "ok",
     "timestamp": 1745778518851,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "nTwTFZEbS-UC",
    "outputId": "0dbea294-9b09-4a1f-bad5-26fe8c0b0ceb"
   },
   "outputs": [],
   "source": [
    "best_parameter_search (TfidfVectorizer(), x_stem, y_stem, x_stem_val, y_stem_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnmdmraHeCtK"
   },
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VhzKBhNeG3h"
   },
   "source": [
    "Parameters:\n",
    "- ngram_range: (1,1) or (1,2)\n",
    "- max_features: 5000, 10 000, 15 000, 20 0000, 25 000\n",
    "- alpha: 0.1, 0.5 and 1\n",
    "\n",
    "The best parameters are ngram_range (1,1), max features 10,000 and alpha 1. On the stemmed set the model performs marginally better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8891,
     "status": "ok",
     "timestamp": 1745778527743,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "kc9Jroe-eYHc",
    "outputId": "1d353a84-dcb2-472f-9742-08ef35c9d1f5"
   },
   "outputs": [],
   "source": [
    "best_parameter_search (CountVectorizer(), x_lem, y_lem, x_lem_val, y_lem_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8928,
     "status": "ok",
     "timestamp": 1745778536675,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "C-4jaR5dedMV",
    "outputId": "69569be9-9b66-4034-8c5c-857f4f65ef2f"
   },
   "outputs": [],
   "source": [
    "best_parameter_search (CountVectorizer(), x_stem, y_stem, x_stem_val, y_stem_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFv2CthfmWAd"
   },
   "source": [
    "### Hash Vectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqQHBVozmYxh"
   },
   "source": [
    "Parameters:\n",
    "- n_features: 20^10, 2^13, 2^15, 2^17, 2^20\n",
    "- alpha: 0.1, 0.5 and 1\n",
    "\n",
    "The best parameters are ngram_range (1,1), n features 2^15 for lemmatized and 2^16 for stemmed set and alpha 1 for bot sets. On the lemmatized set the model performs marginally better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745778536677,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "7Y4UJekFmu6J"
   },
   "outputs": [],
   "source": [
    "def best_parameter_search_hash (vectorizer, X_train, y_train, X_val, y_val):\n",
    "\n",
    "  pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', MultinomialNB())\n",
    "  ])\n",
    "\n",
    "  # Grid of hyperparameters\n",
    "  param_grid = {\n",
    "      'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "      'vectorizer__n_features': [2**10, 2**12, 2**14, 2**15, 2**16],\n",
    "      'classifier__alpha': [0.1, 0.5, 1.0]\n",
    "  }\n",
    "\n",
    "  # Grid search only on training data\n",
    "  grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  # Best model from grid search\n",
    "  best_model = grid_search.best_estimator_\n",
    "\n",
    "  # Evaluate on validation set\n",
    "  y_pred = best_model.predict(X_val)\n",
    "\n",
    "  # Print evaluation metrics\n",
    "  print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "  print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "  print(\"Best Parameters:\", grid_search.best_params_)\n",
    "  print(\"Best Cross-Validation Score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5262,
     "status": "ok",
     "timestamp": 1745778541958,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "PG7nUmO2nBu9",
    "outputId": "6dadc464-dcbe-4e5b-9368-6962ab200c05"
   },
   "outputs": [],
   "source": [
    "best_parameter_search_hash (HashingVectorizer(alternate_sign=False), x_lem, y_lem, x_lem_val, y_lem_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5469,
     "status": "ok",
     "timestamp": 1745778547425,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "KBH4QSjknj7_",
    "outputId": "685eb066-188f-4f21-be78-56e0283bef8d"
   },
   "outputs": [],
   "source": [
    "best_parameter_search_hash (HashingVectorizer(alternate_sign=False), x_stem, y_stem, x_stem_val, y_stem_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1745779292405,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "OyRiUHjtuIqg"
   },
   "outputs": [],
   "source": [
    "# train and save the best model\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=10000)\n",
    "X_train_count = vectorizer.fit_transform(x_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1745779295403,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "c6g9Y_mSuTNc",
    "outputId": "155b7e0f-eca0-4508-daba-a5f543f78f9d"
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB(alpha = 1)\n",
    "nb_classifier.fit(X_train_count, y_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1745780414085,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "yQAd7H-0dwcG",
    "outputId": "d0bd7672-46ef-4096-d686-550edbe5e085"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, \"/content/drive/My Drive/BA THESIS/trained_nb_model/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save the trained Naïve Bayes model\n",
    "joblib.dump(nb_classifier, \"/content/drive/My Drive/BA THESIS/trained_nb_model/naive_bayes_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0CehEaEs9hM"
   },
   "source": [
    "The differences between vectorizers and lemmatizing or stemming are marginal. The highest validation accuracy was the determining factor for the chosen model. This is **TFIDF vectorizer with ngram_range (1,2) and 20 000 features** on the **lemmatized** set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8cQxYrLN9wr"
   },
   "source": [
    "# BERT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfmGyYEzOBX4"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchaudio torchvision torchtext torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krHfJbzOolHT"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWqM5NiN8pk_"
   },
   "outputs": [],
   "source": [
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9864,
     "status": "ok",
     "timestamp": 1745779363723,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "A0jxr-62vFTA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfO922Oj4ufj"
   },
   "source": [
    "Labels are encoded as 0,1 and 2. Then the tokenizer function is defined to accomodate to the longest text inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1745779385666,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "oIpssgUiu7dp"
   },
   "outputs": [],
   "source": [
    "# encode labels as 0,1,2\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_BERT[\"label\"] = label_encoder.fit_transform(train_BERT[\"ground_truth\"])\n",
    "val_BERT[\"label\"] = label_encoder.transform(val_BERT[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "7c953714b8014e999d23d5bfa32c7ed8",
      "964e19ce363c41e79bda58ba0dba9622",
      "f2451d54546e496290fe87dfe0fcded5",
      "11419e23502f4f45b9472bb119ae6c5d",
      "2ed3209704fd43639f43a7913080e3d6",
      "6aea142c973c4978b59fb1788bffaa2c",
      "9acfe2e539d84db6bf3e991e8b21e843",
      "d0cc80cf562249d09f11ee141b41a9ed",
      "dab8be9dbd214c30b450a438f781591b",
      "e325a543ecb74823b5bc367cf0602ed5",
      "6cc700dbfdd947949fd50d1a4cb8e71c",
      "18b42d8a2652400c9f88605677028f4e",
      "4abb097639b941c98b05c188e41a9a4c",
      "cbb8b2ac4fce49bb8391042e48660b87",
      "ca23cffe37ce454c875f6897c0263d17",
      "97db2b7d43394605b2baa9b08a61464c",
      "6a9e4aff29ef4337ba147f97f50ebe84",
      "ab1bae94719248bf84e307f270496229",
      "3cbdbec843f343bd9d0c66d537315951",
      "2ce112ac9b0e43baaec7d064b8bac03c",
      "e79aab30652a4c1f920906853d272d7b",
      "bac9ec005a6b4fef91b12fd5f6f1ce3d",
      "d85e023c99bc40ccb7e99f2fb0156922",
      "3b41abeb576c46a590c578fab6af5d7c",
      "73dcf0326e5045ebbc743d374c710af7",
      "7ff16de0ce214d49adf0eb1aec816ee7",
      "3e94e557a13d429195e10925882701cc",
      "449beef76b80447f828a7078373c384f",
      "2be732837f414b09b3d0250775ffb891",
      "76a425fdd3f9438e82721391be29bd10",
      "bf511d52c794493b9c4049ee5a52ee64",
      "76e1ccc5b57044d698c5fdf04f41db0a",
      "87ca458f88de499b945297dca6ca3f0f",
      "781824710060499fa7621e7f225492f7",
      "19a0c531b75d4f4195051d1ef597b577",
      "21e6b869ee734f7ba8dd0fc7a5325f99",
      "5b9539dabf6347da87523bdd9f550476",
      "a1ad46922c9e4b85b2e0d779c840ef58",
      "b97d2dc3074a4674a9f1c8832552113d",
      "19171e21352b487d92b7976a077d2626",
      "b959cefadc0e4642bfbfc80386458e1d",
      "4ff0865c4a92488ba44293af8734ccf0",
      "5720013d00974ffab15f272bd04fb8e3",
      "4cfa40ff565748c88d95851095dc2d42"
     ]
    },
    "executionInfo": {
     "elapsed": 4251,
     "status": "ok",
     "timestamp": 1745779392922,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "ubZu0T2tBjDp",
    "outputId": "f5d50677-e068-4c16-81fe-fb8574733718"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6759,
     "status": "ok",
     "timestamp": 1745779452913,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "5-T1G5gRvkNF"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(text):\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",    # or use \"longest\" for dynamic padding\n",
    "        max_length=200,       # since we are using headlines\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize texts and extract tensors\n",
    "tokenized_train = tokenize_function(train_BERT[\"text\"].tolist())\n",
    "tokenized_val = tokenize_function(val_BERT[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1745779456110,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "Dim7vGBbvkhp"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert labels to a TensorFlow tensor\n",
    "labels_train = tf.convert_to_tensor(train_BERT[\"label\"].tolist())\n",
    "labels_val = tf.convert_to_tensor(val_BERT[\"label\"].tolist())\n",
    "\n",
    "# Create a dataset from the dictionary and labels\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        \"input_ids\": tokenized_train[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized_train[\"attention_mask\"]\n",
    "    },\n",
    "    labels_train\n",
    "))\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        \"input_ids\": tokenized_val[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized_val[\"attention_mask\"]\n",
    "    },\n",
    "    labels_val\n",
    "))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLonvvEV6YfV"
   },
   "source": [
    "The hyperparameter optimization is split into two parts instead of a traditional grid search. This is due to computing power required if all combinations of the three hyperparameters are searched.\n",
    "\n",
    "In the first round the best combination of learning rate and batch size is search. The considered batch sizes are 16 and 32, the considered learning rates are 2e-5, 3e-5, 5e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1745779463511,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "7f05GHmY3bIA"
   },
   "outputs": [],
   "source": [
    "learning_rates = [2e-5, 3e-5, 5e-5]\n",
    "batch_sizes = [16, 32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "99647682326544f891f3e12a6cc629af",
      "8aeb54db871a41e8a20f1ae200abff9a",
      "e4c45be20ee24b6aab059ddd1147cfb5",
      "397c01deb7124ba1abd2f2bafb50dd91",
      "5efde1fa2f434bbb9038eda2c6b18873",
      "d2656ae89dbd466b8710d5ae9f7601df",
      "b69c4b8a1a044871824f50c7b0fde0ad",
      "d7d6b70b03694394bf47a3587a8e1580",
      "3ca58e33ed6540f098111c0c5209418a",
      "2e0442d9fb61487bb715e5a92d4e75eb",
      "f2cba9d92f12468d97dadbb85747e5fe"
     ]
    },
    "executionInfo": {
     "elapsed": 882133,
     "status": "ok",
     "timestamp": 1745780357820,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "pLvTxXyh3uYR",
    "outputId": "b11e46bd-8959-47db-b118-e611c55fa1b2"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "\n",
    "          print(f\"Training with lr: {lr}, batch_size: {batch_size}\")\n",
    "\n",
    "          # Create batched datasets for current batch size\n",
    "          train_dataset = dataset_train.shuffle(buffer_size=len(train_BERT)).batch(batch_size)\n",
    "          val_dataset = dataset_val.batch(batch_size)\n",
    "\n",
    "          # Load and compile the model\n",
    "          model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "          optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "          loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "          model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "          # Train the model\n",
    "          history = model.fit(train_dataset, validation_data=val_dataset, epochs=1)\n",
    "\n",
    "          # Evaluate the model on validation dataset\n",
    "          eval_results = model.evaluate(val_dataset, verbose=0)\n",
    "          val_accuracy = eval_results[1]\n",
    "\n",
    "          # Compute F1 score manually:\n",
    "          # 1. Collect predictions and true labels\n",
    "          all_preds = []\n",
    "          all_labels = []\n",
    "          for batch in val_dataset:\n",
    "              inputs, labels = batch\n",
    "              logits = model(inputs, training=False).logits\n",
    "              preds = tf.argmax(logits, axis=-1).numpy()\n",
    "              all_preds.extend(preds)\n",
    "              all_labels.extend(labels.numpy())\n",
    "\n",
    "            # Calculate F1 score (macro-average)\n",
    "          val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "            # Save the hyperparameters and metrics\n",
    "          results.append({\n",
    "              \"learning_rate\": lr,\n",
    "              \"batch_size\": batch_size,\n",
    "              \"val_accuracy\": val_accuracy,\n",
    "              \"val_f1\": val_f1\n",
    "          })\n",
    "          print(f\"Finished: Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}\\n\")\n",
    "\n",
    "# Print all results\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1745780378226,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "tMatGhkV3uKy"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/content/drive/My Drive/BA THESIS/graphs/training/grid_search_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1745780381818,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "qReTFbc23a3D",
    "outputId": "6aaa0210-c363-4fe4-a3fb-f8a9acaf4be1"
   },
   "outputs": [],
   "source": [
    "# laod in training results\n",
    "\n",
    "file_path_results = \"/content/drive/My Drive/BA THESIS/graphs/training/grid_search_results.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "results = pd.read_csv(file_path_results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745780388445,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "sJgoCO63Qo1t"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1745780393694,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "j9dh7sUoQp-6",
    "outputId": "ff81ed89-bcd2-4d22-d8e6-d17c3ed0bc4c"
   },
   "outputs": [],
   "source": [
    "batch_sizes = results['batch_size'].unique()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for bs in batch_sizes:\n",
    "    # Select rows for the current batch size\n",
    "    subset = results[results['batch_size'] == bs]\n",
    "    # Sort by learning_rate for smooth line plot\n",
    "    subset = subset.sort_values('learning_rate')\n",
    "    plt.plot(subset['learning_rate'], subset['val_accuracy'], marker='o', label=f'Batch Size {bs}')\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs Learning Rate for Different Batch Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"/content/drive/My Drive/BA THESIS/graphs/training/validation_accuracy_vs_learning_rate.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1745780401683,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "UTBLzzOjQ8wv",
    "outputId": "fdce5611-4f7b-419e-8b63-8fb0f5b0f4aa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for bs in batch_sizes:\n",
    "    # Select rows for the current batch size\n",
    "    subset = results[results['batch_size'] == bs]\n",
    "    # Sort by learning_rate for smooth line plot\n",
    "    subset = subset.sort_values('learning_rate')\n",
    "    plt.plot(subset['learning_rate'], subset['val_f1'], marker='o', label=f'Batch Size {bs}')\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('F1 score vs Learning Rate for Different Batch Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/graphs/training/f1_vs_learning_rate.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC3TD_lhRklJ"
   },
   "source": [
    "We can see that overall smaller batch size yields better results, and the learning rate of 3e-5 yields the best results. These parameters we will keep fixed and train over multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMQMtPz06Ewz"
   },
   "source": [
    "Now, we fix the batch size at 16 and the learning rate at 3e-5 and optimize for the number of epochs. The search range is 1 to 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1558153,
     "status": "ok",
     "timestamp": 1745782015854,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "fY6Y2twFSIOr",
    "outputId": "c02e0302-71b7-4de8-bda0-c5cbb75b0453"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fixed hyperparameters\n",
    "fixed_batch_size = 16\n",
    "fixed_learning_rate = 3e-5\n",
    "epoch_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "train_dataset = dataset_train.shuffle(buffer_size=len(train_BERT)).batch(fixed_batch_size)\n",
    "val_dataset = dataset_val.batch(fixed_batch_size)\n",
    "\n",
    "for num_epochs in epoch_list:\n",
    "    print(f\"Training for {num_epochs} epochs with batch size {fixed_batch_size} and learning rate {fixed_learning_rate}\")\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "\n",
    "    # Load and compile the model\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=fixed_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs, verbose=1)\n",
    "\n",
    "    # Evaluate the model on the validation dataset for accuracy\n",
    "    eval_results = model.evaluate(val_dataset, verbose=0)\n",
    "    val_accuracy = eval_results[1]\n",
    "\n",
    "    # Compute F1 score manually\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in val_dataset:\n",
    "        inputs, labels = batch\n",
    "        logits = model(inputs, training=False).logits\n",
    "        preds = tf.argmax(logits, axis=-1).numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Save the metrics and hyperparameter info in the results list\n",
    "    results.append({\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": fixed_batch_size,\n",
    "        \"learning_rate\": fixed_learning_rate,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"val_f1\": val_f1\n",
    "    })\n",
    "\n",
    "    print(f\"Finished {num_epochs} epochs: Accuracy = {val_accuracy:.4f}, F1 = {val_f1:.4f}\\n\")\n",
    "\n",
    "    # Clean up model from memory\n",
    "    del model\n",
    "\n",
    "# Print results\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1745782028224,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "B8eGet1DQ9K4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/content/drive/My Drive/BA THESIS/graphs/training/epochs_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlVONxJOs3l7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hN2b9yYFxj3K"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1745782038739,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "5Zl73cx8Rd00",
    "outputId": "0edf3085-b12f-4f83-f132-c3d61b375904"
   },
   "outputs": [],
   "source": [
    "# laod in training results\n",
    "\n",
    "file_path_epochs = \"/content/drive/My Drive/BA THESIS/graphs/training/epochs_results.csv\"\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "epochs = pd.read_csv(file_path_epochs)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1745782045621,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "MJLxapBYRM_5",
    "outputId": "b4fcda37-6aec-48f6-91bd-703745f2190d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(epochs['epochs'], epochs['val_accuracy'], marker='o')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy for Different Number of Epochs')\n",
    "plt.grid(True)\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/graphs/training/validation_accuracy_vs_epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1745782055291,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "1XrlIaUzR9wv",
    "outputId": "355c4d94-7d02-4675-d427-ff0e7f727c9e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(epochs['epochs'], epochs['val_f1'], marker='o')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('F1 score for Different Number of Epochs')\n",
    "plt.grid(True)\n",
    "plt.savefig('/content/drive/My Drive/BA THESIS/graphs/training/f1_vs_epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjLTjnNTS1S0"
   },
   "source": [
    "From the graph we can see that the last significant improvement happens when we increase the number of epochs from 1 to 2. As the increase of epochs linearly increases complexity, it is only worth to do an additional epoch when it yields significant increae in accuracy or F1 score. From the graphs and the table we can decide to chose the model that ha sbeen trained for only 2 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPkfacD5ujVH"
   },
   "source": [
    "### Train and save final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmuM8geGIkHU"
   },
   "source": [
    "Now we train and save the model with the final hyperparameters that are:\n",
    "- batch size: 16\n",
    "- learning rate: 3e-5\n",
    "- epochs: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1745782082778,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "CdtW8UEe3auX"
   },
   "outputs": [],
   "source": [
    "# Shuffle and batch the dataset\n",
    "batch_size = 16\n",
    "dataset_train = dataset_train.shuffle(buffer_size=len(train_BERT)).batch(batch_size)\n",
    "dataset_val = dataset_val.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1364,
     "status": "ok",
     "timestamp": 1745782085473,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "bgslRMGuCdkg",
    "outputId": "3e38556c-6e24-4853-9d52-8190e245b06a"
   },
   "outputs": [],
   "source": [
    "# Positive, negative, neutral classification, num_labels=3\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Compile the model with an optimizer, loss, and metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206447,
     "status": "ok",
     "timestamp": 1745782293889,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "rc8O2Vs0Cqv9",
    "outputId": "d9858f14-3787-4463-d6c6-b86c27fa93aa"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    validation_data=dataset_val,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4065,
     "status": "ok",
     "timestamp": 1745782336254,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "2I8il5JoC4Ky",
    "outputId": "22d9b70c-59c5-4017-9b1c-b90973a6ee93"
   },
   "outputs": [],
   "source": [
    "eval_results = model.evaluate(dataset_val)\n",
    "print(f\"Validation Loss: {eval_results[0]:.4f}, Validation Accuracy: {eval_results[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1745782342603,
     "user": {
      "displayName": "Mira Radakovic",
      "userId": "13106905781290647575"
     },
     "user_tz": -120
    },
    "id": "mr50wxT5zv3e",
    "outputId": "4a4da843-ba2d-44ed-f5df-d365dad70571"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"/content/drive/My Drive/BA THESIS/trained_bert_model/bert_model\")\n",
    "\n",
    "# Save the tokenizer (important for preprocessing when using the model later)\n",
    "tokenizer.save_pretrained(\"/content/drive/My Drive/BA THESIS/trained_bert_model/bert_tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO4mKsXOD1nOpf5mU0Nyvko",
   "gpuType": "A100",
   "mount_file_id": "1ZLQrICi8-B660Z-7IuZbXMAUFzDPsUap",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
